{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XUjUkU49tL26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3992fa-118c-421d-f3e6-ddb5adf03662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# bootstrap block\n",
        "\n",
        "#!pip -q install -r requirements.txt\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "REPO_URL = \"https://github.com/AmjadKudsi/Meta_llama-chatbot.git\"\n",
        "REPO_DIR = \"/content/rag-chatbot\"\n",
        "\n",
        "CONFIG_PATH = \"/content/rag-chatbot/configs/app.yaml\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    %cd {REPO_DIR}\n",
        "    !git pull\n",
        "\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "\n",
        "with open(CONFIG_PATH, \"r\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "paths = cfg[\"paths\"]\n",
        "DOCS_DIR = paths[\"docs_dir\"]\n",
        "INDEX_DIR = paths[\"index_dir\"]\n",
        "EVAL_RUNS_DIR = paths[\"eval_runs_dir\"]\n",
        "TRACES_DIR = paths[\"traces_dir\"]\n",
        "\n",
        "rag_cfg = cfg.get(\"rag\", {})\n",
        "TOP_K = rag_cfg.get(\"top_k\", 6)\n",
        "CHUNK_SIZE = rag_cfg.get(\"chunk_size\", 900)\n",
        "CHUNK_OVERLAP = rag_cfg.get(\"chunk_overlap\", 150)\n",
        "\n",
        "print(\"DOCS_DIR:\", DOCS_DIR)\n",
        "print(\"INDEX_DIR:\", INDEX_DIR)\n",
        "print(\"TOP_K:\", TOP_K)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "import glob, os\n",
        "pdfs = glob.glob(DOCS_DIR + \"/*.pdf\")\n",
        "print(\"PDFs found:\", len(pdfs))\n",
        "print(\"Example:\", os.path.basename(pdfs[0]) if pdfs else \"None\")"
      ],
      "metadata": {
        "id": "31ww_LLx2e5n",
        "outputId": "b57dd6ff-1c24-44a0-a1a5-9a2bc49b8f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDFs found: 10\n",
            "Example: tax01.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rlOg1xD-2iC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}